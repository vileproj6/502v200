#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v2.0 - Intelligent Query Generator
Gerador inteligente de queries para pesquisa aprimorada
"""

import logging
import re
from typing import Dict, List, Any, Set
from datetime import datetime

logger = logging.getLogger(__name__)

class IntelligentQueryGenerator:
    """Gerador inteligente de queries para pesquisa abrangente"""
    
    def __init__(self):
        """Inicializa gerador de queries"""
        self.query_templates = self._load_query_templates()
        self.segment_keywords = self._load_segment_keywords()
        self.market_intelligence_terms = self._load_market_intelligence_terms()
        
        logger.info("Intelligent Query Generator inicializado")
    
    def _load_query_templates(self) -> Dict[str, List[str]]:
        """Carrega templates de queries por categoria"""
        return {
            'market_analysis': [
                "mercado {segmento} Brasil 2024 tamanho crescimento dados",
                "an√°lise {segmento} estat√≠sticas IBGE consumo demanda",
                "setor {segmento} brasileiro faturamento receita participa√ß√£o",
                "ind√∫stria {segmento} Brasil n√∫meros dados oficiais",
                "economia {segmento} PIB contribui√ß√£o impacto econ√¥mico"
            ],
            'competition': [
                "principais empresas {segmento} Brasil l√≠deres mercado",
                "concorr√™ncia {segmento} market share participa√ß√£o",
                "ranking empresas {segmento} brasileiras maiores",
                "competi√ß√£o {segmento} an√°lise competitiva SWOT",
                "players {segmento} Brasil unic√≥rnios startups"
            ],
            'trends_innovation': [
                "tend√™ncias {segmento} 2024 2025 futuro inova√ß√£o",
                "inova√ß√£o {segmento} tecnologia disrup√ß√£o mudan√ßas",
                "futuro {segmento} predi√ß√µes especialistas consultoria",
                "transforma√ß√£o digital {segmento} automa√ß√£o IA",
                "evolu√ß√£o {segmento} pr√≥ximos anos cen√°rios"
            ],
            'investment_funding': [
                "investimentos {segmento} venture capital funding rodadas",
                "aportes {segmento} startups unic√≥rnios valuations",
                "fus√µes aquisi√ß√µes {segmento} M&A consolida√ß√£o",
                "IPO {segmento} bolsa valores B3 abertura capital",
                "private equity {segmento} investidores fundos"
            ],
            'regulation_compliance': [
                "regulamenta√ß√£o {segmento} leis normas compliance",
                "legisla√ß√£o {segmento} mudan√ßas legais impacto",
                "normas {segmento} ANVISA ANATEL reguladores",
                "compliance {segmento} adequa√ß√£o legal requisitos",
                "marco legal {segmento} PL projetos lei"
            ],
            'consumer_behavior': [
                "comportamento consumidor {segmento} pesquisa h√°bitos",
                "perfil consumidor {segmento} demogr√°fico psicogr√°fico",
                "jornada compra {segmento} processo decis√£o fatores",
                "prefer√™ncias consumidor {segmento} tend√™ncias consumo",
                "experi√™ncia cliente {segmento} satisfa√ß√£o NPS"
            ],
            'pricing_economics': [
                "pre√ßos {segmento} ticket m√©dio benchmarks mercado",
                "precifica√ß√£o {segmento} estrat√©gias modelos neg√≥cio",
                "elasticidade pre√ßo {segmento} sensibilidade consumidor",
                "margens {segmento} rentabilidade lucratividade",
                "custos {segmento} estrutura despesas operacionais"
            ],
            'distribution_channels': [
                "canais distribui√ß√£o {segmento} vendas marketplace",
                "e-commerce {segmento} vendas online digital",
                "varejo {segmento} pontos venda distribui√ß√£o",
                "log√≠stica {segmento} supply chain distribui√ß√£o",
                "parcerias {segmento} canais indiretos revendas"
            ]
        }
    
    def _load_segment_keywords(self) -> Dict[str, List[str]]:
        """Carrega palavras-chave espec√≠ficas por segmento"""
        return {
            'tecnologia': [
                'software', 'hardware', 'SaaS', 'cloud', 'IA', 'machine learning',
                'blockchain', 'IoT', 'big data', 'analytics', 'cybersecurity',
                'fintech', 'healthtech', 'edtech', 'proptech', 'agtech'
            ],
            'saude': [
                'medicina', 'hospitais', 'cl√≠nicas', 'telemedicina', 'farm√°cia',
                'biotecnologia', 'dispositivos m√©dicos', 'diagn√≥stico', 'terapia',
                'SUS', 'planos sa√∫de', 'ANS', 'ANVISA', 'CFM'
            ],
            'educacao': [
                'ensino', 'universidades', 'escolas', 'cursos', 'treinamento',
                'capacita√ß√£o', 'EAD', 'e-learning', 'MEC', 'INEP',
                'educa√ß√£o b√°sica', 'ensino superior', 'p√≥s-gradua√ß√£o'
            ],
            'financeiro': [
                'bancos', 'fintechs', 'pagamentos', 'cr√©dito', 'investimentos',
                'seguros', 'previd√™ncia', 'Bacen', 'CVM', 'Susep',
                'PIX', 'open banking', 'DeFi', 'criptomoedas'
            ],
            'varejo': [
                'e-commerce', 'marketplace', 'omnichannel', 'retail',
                'consumo', 'FMCG', 'moda', 'alimenta√ß√£o', 'casa',
                'shopping centers', 'franquias', 'atacado', 'distribui√ß√£o'
            ],
            'agronegocio': [
                'agricultura', 'pecu√°ria', 'agtech', 'commodities',
                'exporta√ß√£o', 'soja', 'milho', 'caf√©', 'carne',
                'sustentabilidade', 'ESG', 'rastreabilidade'
            ]
        }
    
    def _load_market_intelligence_terms(self) -> List[str]:
        """Carrega termos de intelig√™ncia de mercado"""
        return [
            'dados', 'estat√≠sticas', 'pesquisa', 'relat√≥rio', 'estudo',
            'an√°lise', 'insights', 'tend√™ncias', 'proje√ß√µes', 'cen√°rios',
            'benchmarks', 'KPIs', 'm√©tricas', 'indicadores', 'performance',
            'crescimento', 'expans√£o', 'oportunidades', 'amea√ßas', 'riscos',
            'inova√ß√£o', 'disrup√ß√£o', 'transforma√ß√£o', 'evolu√ß√£o', 'mudan√ßas'
        ]
    
    def generate_comprehensive_queries(
        self, 
        base_query: str, 
        context: Dict[str, Any],
        max_queries: int = 20
    ) -> List[str]:
        """Gera queries abrangentes para pesquisa"""
        
        segmento = context.get('segmento', '').lower()
        produto = context.get('produto', '')
        publico = context.get('publico', '')
        
        logger.info(f"üß† Gerando queries inteligentes para: {segmento}")
        
        all_queries = [base_query]  # Inclui query original
        
        # 1. Queries baseadas em templates
        template_queries = self._generate_from_templates(segmento, produto, publico)
        all_queries.extend(template_queries)
        
        # 2. Queries espec√≠ficas do segmento
        segment_queries = self._generate_segment_specific_queries(segmento, produto)
        all_queries.extend(segment_queries)
        
        # 3. Queries de intelig√™ncia de mercado
        intelligence_queries = self._generate_market_intelligence_queries(segmento, context)
        all_queries.extend(intelligence_queries)
        
        # 4. Queries temporais (tend√™ncias)
        temporal_queries = self._generate_temporal_queries(segmento, produto)
        all_queries.extend(temporal_queries)
        
        # 5. Queries geogr√°ficas (Brasil espec√≠fico)
        geographic_queries = self._generate_geographic_queries(segmento, produto)
        all_queries.extend(geographic_queries)
        
        # Remove duplicatas e queries muito similares
        unique_queries = self._deduplicate_and_rank_queries(all_queries, context)
        
        # Retorna top queries
        final_queries = unique_queries[:max_queries]
        
        logger.info(f"‚úÖ {len(final_queries)} queries inteligentes geradas")
        
        return final_queries
    
    def _generate_from_templates(self, segmento: str, produto: str, publico: str) -> List[str]:
        """Gera queries a partir de templates"""
        
        queries = []
        
        for category, templates in self.query_templates.items():
            for template in templates:
                # Substitui placeholders
                query = template.format(segmento=segmento)
                
                # Adiciona produto se dispon√≠vel
                if produto and '{produto}' not in template:
                    query = query.replace(segmento, f"{segmento} {produto}")
                
                queries.append(query)
        
        return queries
    
    def _generate_segment_specific_queries(self, segmento: str, produto: str) -> List[str]:
        """Gera queries espec√≠ficas do segmento"""
        
        queries = []
        
        # Identifica segmento principal
        segment_key = self._identify_segment_category(segmento)
        
        if segment_key in self.segment_keywords:
            keywords = self.segment_keywords[segment_key]
            
            # Combina segmento com palavras-chave espec√≠ficas
            for keyword in keywords[:10]:  # Top 10 keywords
                queries.extend([
                    f"{segmento} {keyword} Brasil mercado dados",
                    f"an√°lise {keyword} {segmento} oportunidades",
                    f"tend√™ncias {keyword} {segmento} 2024"
                ])
        
        # Queries espec√≠ficas por produto
        if produto:
            queries.extend([
                f"demanda {produto} {segmento} Brasil consumo",
                f"concorrentes {produto} {segmento} an√°lise",
                f"pre√ßo {produto} {segmento} benchmarks",
                f"inova√ß√£o {produto} {segmento} tecnologia"
            ])
        
        return queries
    
    def _generate_market_intelligence_queries(self, segmento: str, context: Dict[str, Any]) -> List[str]:
        """Gera queries de intelig√™ncia de mercado"""
        
        queries = []
        
        # Combina segmento com termos de intelig√™ncia
        for term in self.market_intelligence_terms[:15]:
            queries.append(f"{term} {segmento} Brasil 2024")
        
        # Queries de fontes espec√≠ficas
        intelligence_sources = [
            'McKinsey', 'BCG', 'Deloitte', 'PwC', 'KPMG',
            'Bain', 'Accenture', 'EY', 'Oliver Wyman'
        ]
        
        for source in intelligence_sources[:5]:
            queries.append(f"{source} relat√≥rio {segmento} Brasil")
        
        # Queries de institutos brasileiros
        brazilian_institutes = [
            'IBGE', 'FGV', 'IPEA', 'CNI', 'FIESP',
            'Sebrae', 'BNDES', 'Banco Central'
        ]
        
        for institute in brazilian_institutes[:5]:
            queries.append(f"{institute} dados {segmento} Brasil")
        
        return queries
    
    def _generate_temporal_queries(self, segmento: str, produto: str) -> List[str]:
        """Gera queries temporais para capturar tend√™ncias"""
        
        queries = []
        
        # Queries por per√≠odo
        time_periods = [
            '2024', '2025', '√∫ltimos 12 meses', 'pr√≥ximos anos',
            'p√≥s-pandemia', 'atual cen√°rio', 'nova era'
        ]
        
        for period in time_periods:
            queries.extend([
                f"{segmento} {period} crescimento tend√™ncias",
                f"mercado {segmento} {period} oportunidades",
                f"futuro {segmento} {period} predi√ß√µes"
            ])
        
        # Queries de evolu√ß√£o
        evolution_terms = [
            'evolu√ß√£o', 'transforma√ß√£o', 'mudan√ßas', 'revolu√ß√£o',
            'disrup√ß√£o', 'inova√ß√£o', 'moderniza√ß√£o'
        ]
        
        for term in evolution_terms:
            queries.append(f"{term} {segmento} Brasil impacto")
        
        return queries
    
    def _generate_geographic_queries(self, segmento: str, produto: str) -> List[str]:
        """Gera queries geogr√°ficas espec√≠ficas do Brasil"""
        
        queries = []
        
        # Regi√µes brasileiras
        regions = [
            'Sudeste', 'Sul', 'Nordeste', 'Centro-Oeste', 'Norte',
            'S√£o Paulo', 'Rio de Janeiro', 'Minas Gerais', 'Paran√°', 'Bahia'
        ]
        
        for region in regions[:8]:
            queries.extend([
                f"{segmento} {region} mercado regional",
                f"empresas {segmento} {region} principais"
            ])
        
        # Contexto brasileiro espec√≠fico
        brazilian_context = [
            'economia brasileira', 'mercado interno', 'consumidor brasileiro',
            'empresas nacionais', 'ind√∫stria nacional', 'setor privado',
            'pol√≠ticas p√∫blicas', 'ambiente regulat√≥rio'
        ]
        
        for context_term in brazilian_context:
            queries.append(f"{segmento} {context_term} impacto")
        
        return queries
    
    def _identify_segment_category(self, segmento: str) -> str:
        """Identifica categoria do segmento"""
        
        segmento_lower = segmento.lower()
        
        # Mapeia segmento para categoria
        segment_mapping = {
            'tecnologia': ['tecnologia', 'software', 'digital', 'tech', 'TI', 'sistemas'],
            'saude': ['sa√∫de', 'medicina', 'm√©dico', 'hospital', 'cl√≠nica', 'farm√°cia'],
            'educacao': ['educa√ß√£o', 'ensino', 'escola', 'curso', 'treinamento'],
            'financeiro': ['financeiro', 'banco', 'fintech', 'pagamento', 'cr√©dito'],
            'varejo': ['varejo', 'com√©rcio', 'loja', 'e-commerce', 'marketplace'],
            'agronegocio': ['agro', 'agricultura', 'pecu√°ria', 'rural', 'campo']
        }
        
        for category, keywords in segment_mapping.items():
            if any(keyword in segmento_lower for keyword in keywords):
                return category
        
        return 'tecnologia'  # Default
    
    def _deduplicate_and_rank_queries(self, queries: List[str], context: Dict[str, Any]) -> List[str]:
        """Remove duplicatas e ranqueia queries por relev√¢ncia"""
        
        # Remove duplicatas exatas
        unique_queries = list(dict.fromkeys(queries))
        
        # Remove queries muito similares
        filtered_queries = []
        
        for query in unique_queries:
            if not any(self._queries_too_similar(query, existing) for existing in filtered_queries):
                filtered_queries.append(query)
        
        # Ranqueia por relev√¢ncia
        ranked_queries = self._rank_queries_by_relevance(filtered_queries, context)
        
        return ranked_queries
    
    def _queries_too_similar(self, query1: str, query2: str, threshold: float = 0.7) -> bool:
        """Verifica se duas queries s√£o muito similares"""
        
        words1 = set(query1.lower().split())
        words2 = set(query2.lower().split())
        
        # Calcula similaridade Jaccard
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        similarity = len(intersection) / len(union) if union else 0
        return similarity > threshold
    
    def _rank_queries_by_relevance(self, queries: List[str], context: Dict[str, Any]) -> List[str]:
        """Ranqueia queries por relev√¢ncia"""
        
        segmento = context.get('segmento', '').lower()
        produto = context.get('produto', '').lower()
        publico = context.get('publico', '').lower()
        
        scored_queries = []
        
        for query in queries:
            score = self._calculate_query_relevance_score(query, segmento, produto, publico)
            scored_queries.append((query, score))
        
        # Ordena por score (maior primeiro)
        scored_queries.sort(key=lambda x: x[1], reverse=True)
        
        return [query for query, score in scored_queries]
    
    def _calculate_query_relevance_score(
        self, 
        query: str, 
        segmento: str, 
        produto: str, 
        publico: str
    ) -> float:
        """Calcula score de relev√¢ncia da query"""
        
        score = 0.0
        query_lower = query.lower()
        
        # Score por men√ß√£o do segmento
        if segmento in query_lower:
            score += 3.0
        
        # Score por men√ß√£o do produto
        if produto and produto in query_lower:
            score += 2.0
        
        # Score por men√ß√£o do p√∫blico
        if publico and any(word in query_lower for word in publico.lower().split()):
            score += 1.5
        
        # Score por termos de alta qualidade
        high_quality_terms = [
            'dados', 'estat√≠sticas', 'an√°lise', 'pesquisa', 'relat√≥rio',
            'brasil', '2024', 'mercado', 'crescimento', 'oportunidades'
        ]
        
        for term in high_quality_terms:
            if term in query_lower:
                score += 0.5
        
        # Score por especificidade (queries mais longas s√£o melhores)
        word_count = len(query.split())
        if word_count >= 6:
            score += 1.0
        elif word_count >= 4:
            score += 0.5
        
        # Penalty por termos muito gen√©ricos
        generic_terms = ['geral', 'b√°sico', 'simples', 'comum']
        for term in generic_terms:
            if term in query_lower:
                score -= 1.0
        
        return score
    
    def generate_follow_up_queries(
        self, 
        initial_results: List[Dict[str, Any]], 
        context: Dict[str, Any]
    ) -> List[str]:
        """Gera queries de follow-up baseadas nos resultados iniciais"""
        
        follow_up_queries = []
        
        # Analisa t√≠tulos dos resultados para identificar temas
        themes = self._extract_themes_from_results(initial_results)
        
        # Gera queries baseadas nos temas encontrados
        for theme in themes[:5]:
            follow_up_queries.extend([
                f"{theme} {context.get('segmento', '')} aprofundamento",
                f"detalhes {theme} {context.get('segmento', '')} Brasil",
                f"an√°lise {theme} impacto {context.get('segmento', '')}"
            ])
        
        # Queries para preencher lacunas
        gap_queries = self._generate_gap_filling_queries(initial_results, context)
        follow_up_queries.extend(gap_queries)
        
        return follow_up_queries[:10]  # Top 10 follow-ups
    
    def _extract_themes_from_results(self, results: List[Dict[str, Any]]) -> List[str]:
        """Extrai temas dos resultados de busca"""
        
        themes = []
        
        # Analisa t√≠tulos e snippets
        all_text = ""
        for result in results:
            title = result.get('title', '')
            snippet = result.get('snippet', '')
            all_text += f" {title} {snippet}"
        
        # Extrai palavras-chave relevantes
        words = re.findall(r'\b[a-z√°√™√ß√µ]{4,}\b', all_text.lower())
        
        # Conta frequ√™ncia
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # Filtra palavras relevantes
        relevant_words = [
            word for word, freq in word_freq.items() 
            if freq >= 2 and word not in ['brasil', 'mercado', 'empresa', 'dados']
        ]
        
        # Ordena por frequ√™ncia
        relevant_words.sort(key=lambda x: word_freq[x], reverse=True)
        
        return relevant_words[:10]
    
    def _generate_gap_filling_queries(
        self, 
        initial_results: List[Dict[str, Any]], 
        context: Dict[str, Any]
    ) -> List[str]:
        """Gera queries para preencher lacunas de informa√ß√£o"""
        
        gap_queries = []
        segmento = context.get('segmento', '')
        
        # Identifica lacunas comuns
        common_gaps = [
            'custos operacionais', 'margens lucro', 'barreiras entrada',
            'cadeia valor', 'fornecedores', 'distribuidores',
            'regulamenta√ß√£o espec√≠fica', 'certifica√ß√µes necess√°rias',
            'sazonalidade mercado', 'ciclos econ√¥micos'
        ]
        
        for gap in common_gaps:
            gap_queries.append(f"{gap} {segmento} Brasil an√°lise")
        
        # Queries para aspectos n√£o cobertos
        if not any('pre√ßo' in r.get('title', '').lower() for r in initial_results):
            gap_queries.append(f"pre√ßos {segmento} Brasil benchmarks")
        
        if not any('regulament' in r.get('title', '').lower() for r in initial_results):
            gap_queries.append(f"regulamenta√ß√£o {segmento} Brasil normas")
        
        if not any('invest' in r.get('title', '').lower() for r in initial_results):
            gap_queries.append(f"investimentos {segmento} Brasil funding")
        
        return gap_queries
    
    def optimize_query_for_search_engine(self, query: str, search_engine: str) -> str:
        """Otimiza query para motor de busca espec√≠fico"""
        
        optimized = query
        
        if search_engine == 'google':
            # Google responde bem a queries espec√≠ficas
            optimized = f'"{query}" OR ({query.replace(" ", " AND ")})'
        
        elif search_engine == 'bing':
            # Bing prefere queries naturais
            optimized = query + " site:*.com.br OR site:*.org.br"
        
        elif search_engine == 'duckduckgo':
            # DuckDuckGo funciona bem com operadores simples
            optimized = query + " !br"
        
        elif search_engine == 'academic':
            # Fontes acad√™micas
            optimized = query + " filetype:pdf OR site:*.edu.br"
        
        return optimized
    
    def generate_negative_keywords(self, context: Dict[str, Any]) -> List[str]:
        """Gera palavras-chave negativas para filtrar resultados irrelevantes"""
        
        negative_keywords = [
            # Termos gen√©ricos irrelevantes
            'login', 'cadastro', 'entrar', 'registrar', 'conta',
            'download', 'baixar', 'instalar', 'app', 'aplicativo',
            'contato', 'sobre', 'quem somos', 'hist√≥ria', 'miss√£o',
            'vagas', 'trabalhe conosco', 'carreiras', 'jobs',
            'termos uso', 'privacidade', 'cookies', 'pol√≠tica',
            
            # Termos de e-commerce irrelevantes
            'comprar', 'pre√ßo', 'oferta', 'promo√ß√£o', 'desconto',
            'carrinho', 'checkout', 'pagamento', 'frete',
            
            # Termos de redes sociais
            'instagram', 'facebook', 'twitter', 'linkedin',
            'youtube', 'tiktok', 'whatsapp', 'telegram',
            
            # Termos t√©cnicos irrelevantes
            'tutorial', 'como fazer', 'passo a passo', 'dicas',
            'truques', 'hacks', 'review', 'an√°lise produto'
        ]
        
        return negative_keywords

# Inst√¢ncia global
intelligent_query_generator = IntelligentQueryGenerator()